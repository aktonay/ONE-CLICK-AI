<a name="top"></a>

<!-- ![heading image](https://raw.githubusercontent.com/aktonay/one-click-ai/main/banner.gif) -->

# ğŸ¤– One Click AI (OCD-AI) ğŸš€

**One Click AI** is a powerful CLI tool that generates **production-ready AI backend projects** in seconds â€” powered by FastAPI, with built-in LLM integration, RAG pipelines, voice, vision, emotion detection, AI agents, **ML training (PyTorch, TensorFlow, scikit-learn, XGBoost, LightGBM)**, **computer vision (YOLO, SAM2, OCR, face detection, image generation)**, **edge AI (ONNX, TensorRT, quantization)**, **LLM fine-tuning (LoRA/QLoRA)**, **AI guardrails (PII, content filter, prompt injection)**, **conversational analytics (Text-to-SQL)**, Docker, CI/CD, IaC, and full observability.

[![PyPI version](https://img.shields.io/pypi/v/one-click-ai)](https://pypi.org/project/one-click-ai/)
[![Python versions](https://img.shields.io/pypi/pyversions/one-click-ai)](https://pypi.org/project/one-click-ai/)
[![License](https://img.shields.io/github/license/aktonay/one-click-ai)](https://github.com/aktonay/one-click-ai/blob/main/LICENSE)
[![GitHub Stars](https://img.shields.io/github/stars/aktonay/one-click-ai?style=social)](https://github.com/aktonay/one-click-ai)

### ğŸ› ï¸ Technology Stack

[![Python](https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![OpenAI](https://img.shields.io/badge/OpenAI-412991?logo=openai&logoColor=white)](https://openai.com)
[![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white)](https://docker.com)
[![Terraform](https://img.shields.io/badge/Terraform-7B42BC?logo=terraform&logoColor=white)](https://terraform.io)
[![Ansible](https://img.shields.io/badge/Ansible-EE0000?logo=ansible&logoColor=white)](https://ansible.com)
[![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?logo=github-actions&logoColor=white)](https://github.com/features/actions)
[![Prometheus](https://img.shields.io/badge/Prometheus-E6522C?logo=prometheus&logoColor=white)](https://prometheus.io)
[![Grafana](https://img.shields.io/badge/Grafana-F46800?logo=grafana&logoColor=white)](https://grafana.com)
[![Redis](https://img.shields.io/badge/Redis-DC382D?logo=redis&logoColor=white)](https://redis.io)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?logo=postgresql&logoColor=white)](https://postgresql.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?logo=pytorch&logoColor=white)](https://pytorch.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?logo=tensorflow&logoColor=white)](https://tensorflow.org)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?logo=scikitlearn&logoColor=white)](https://scikit-learn.org)
[![ONNX](https://img.shields.io/badge/ONNX-005CED?logo=onnx&logoColor=white)](https://onnx.ai)
[![Ultralytics](https://img.shields.io/badge/YOLO-111F68?logo=yolo&logoColor=white)](https://ultralytics.com)
[![Hugging Face](https://img.shields.io/badge/HuggingFace-FFD21E?logo=huggingface&logoColor=black)](https://huggingface.co)
[![Ollama](https://img.shields.io/badge/Ollama-000000?logo=ollama&logoColor=white)](https://ollama.com)

â­ **Star us on GitHub** â€” your support motivates us a lot! ğŸ™ğŸ˜Š

[![Follow Mohammad Asif Khan](https://img.shields.io/badge/Follow-LinkedIn-0A66C2?logo=linkedin)](https://www.linkedin.com/in/mohammad-asif-khan-tonay-795b641b6)
[![Share on LinkedIn](https://img.shields.io/badge/Share-0A66C2?logo=linkedin&logoColor=white)](https://www.linkedin.com/sharing/share-offsite/?url=https://github.com/aktonay/one-click-ai)

---

> Stop copy-pasting boilerplate. Start building what matters.

## ğŸŒŸ The Story Behind One Click AI

Every time a new AI project starts, I see the same cycle â€” developers lose **days** reinventing the same infrastructure:

- **Provider Headaches:** Writing LLM client wrappers for OpenAI, Anthropic, Google, Groq â€” over and over.
- **RAG Nightmares:** Stitching together document ingestion, chunking, embedding, vector stores, and retrieval from scratch.
- **Multimodal Chaos:** Integrating STT, TTS, vision, and emotion detection with no standard structure.
- **Infrastructure Fatigue:** Manually setting up Dockerfiles, CI/CD pipelines, Terraform configs, Prometheus dashboards â€” before writing a single line of AI logic.
- **Confidence Gap:** After hours of wiring, nobody is 100% sure the architecture is production-ready.

**One Click AI** was born to eliminate this. It generates a battle-tested, modular AI backend in **seconds** â€” with every integration wired up, every best practice baked in, and every deployment tool ready to go. No more boilerplate, no more forgotten configs â€” just one command to start building real AI applications.

## ğŸš€ What You Get with `ocd-ai`

When you run `ocd-ai init`, you don't just get a folder â€” you get a **complete AI production environment**:

- **ğŸ§  Multi-Provider LLM:** Pre-configured clients for OpenAI, Anthropic, Google, Groq, Grok, Cohere, Mistral, and Ollama â€” swap providers with a config change.
- **ğŸ“š RAG Pipeline:** Full document ingestion â†’ smart chunking â†’ embedding â†’ vector retrieval â†’ LLM generation pipeline, ready to go.
- **ğŸ¤ Voice & Audio:** Whisper/Deepgram STT + OpenAI/ElevenLabs TTS + real-time voice-to-voice conversation.
- **ğŸ‘ï¸ Vision & Emotion:** Image/video analysis (GPT-4o, Claude, Gemini) + emotion detection (Hume AI + LLM fallback).
- **ğŸ¤– AI Agents:** ReAct-style agents with built-in tool use and web search (Tavily, Serper, DuckDuckGo).
- **ğŸ§  Memory:** Short-term (in-context) + long-term (persistent) conversation memory with session management.
- **âš¡ Streaming:** SSE + WebSocket streaming for real-time responses.
- **ğŸ³ Docker Ready:** Multi-stage Dockerfiles + docker-compose for dev and production with Nginx reverse proxy.
- **âš™ï¸ CI/CD (GitHub Actions):** Pre-configured workflows for testing, linting, and automated deployment.
- **ğŸ—ï¸ Infrastructure as Code:** Terraform templates for AWS + Ansible playbooks for server configuration.
- **ğŸ“Š Monitoring & Observability:** Prometheus metrics + Grafana dashboards + alerting rules â€” all pre-configured.
- **ğŸ“Š Vector Store Flexibility:** Choose from FAISS, Pinecone, Qdrant, Weaviate, ChromaDB, Milvus, or pgvector.
- **ğŸ”’ Standard .gitignore & .env:** Pre-configured environment files with secrets management best practices.
- **ğŸš€ GitHub Integration:** Auto-initializes a git repo and pushes to a new GitHub repository in one go.
- **ğŸ”¬ ML Training Pipelines:** PyTorch, TensorFlow, scikit-learn, XGBoost, LightGBM â€” with trainers, predictors, feature engineering, model registry, and experiment tracking (MLflow/W&B).
- **ğŸ–¼ï¸ Computer Vision:** YOLO (object detection), SAM2 (segmentation), EasyOCR/Tesseract (OCR), face detection/recognition, Stable Diffusion (image generation).
- **âš¡ Edge AI Deployment:** ONNX Runtime, TensorRT conversion, INT8 quantization, model optimization, benchmarking.
- **ğŸ”§ LLM Fine-Tuning:** LoRA/QLoRA fine-tuning with PEFT + Transformers, merge & export for deployment.
- **ğŸ›¡ï¸ AI Guardrails:** Content safety (Detoxify), PII detection/anonymization (Presidio), prompt injection defense, audit logging.
- **ğŸ“Š Conversational Analytics:** Natural language â†’ SQL (Text-to-SQL), auto-chart generation (Plotly), report builder.
- **ğŸ  Ollama Local Deployment:** Self-hosted LLM inference via Ollama in docker-compose.
- **ğŸš€ One-Command Deploy:** Deploy to AWS ECS, Google Cloud Run, Azure Container Apps, DigitalOcean, Railway, Fly.io, Render, or any VPS â€” with `ocd-ai deploy`.

## âœ¨ Feature Matrix

| Feature | Description |
|---------|-------------|
| ğŸ§  **LLM Chat** | Multi-provider support (OpenAI, Anthropic, Google, Groq, Grok, Cohere, Mistral, Ollama) |
| ğŸ“š **RAG Pipeline** | Document ingestion â†’ chunking â†’ embedding â†’ retrieval â†’ generation |
| ğŸ¤ **Voice (STT/TTS)** | Speech-to-Text (Whisper, Deepgram) + Text-to-Speech (OpenAI, ElevenLabs) |
| ğŸ—£ï¸ **Voice-to-Voice** | Real-time audio conversation pipeline |
| ğŸ‘ï¸ **Vision** | Image & video analysis with GPT-4o, Claude, Gemini |
| ğŸ˜Š **Emotion Detection** | Audio/text emotion analysis (Hume AI + LLM fallback) |
| ğŸ” **Web Search** | Internet search (Tavily, Serper, DuckDuckGo) with LLM summarization |
| ğŸ¤– **AI Agents** | ReAct-style agents with tool use |
| ğŸ§  **Memory** | Short-term + long-term conversation memory |
| âš¡ **Streaming** | SSE + WebSocket streaming responses |
| ğŸ” **Sessions** | Persistent session management (Redis-backed) |
| ğŸ“Š **Vector Stores** | FAISS, Pinecone, Qdrant, Weaviate, ChromaDB, Milvus, pgvector |
| ğŸ³ **Docker** | Production + dev Dockerfiles, docker-compose, Nginx |
| ğŸ”„ **CI/CD** | GitHub Actions (test, lint, deploy) |
| ğŸ—ï¸ **IaC** | Terraform (AWS) + Ansible server configuration |
| ğŸ“ˆ **Monitoring** | Prometheus + Grafana + alerts |
| ğŸ”¬ **ML Training** | PyTorch, TensorFlow, scikit-learn, XGBoost, LightGBM pipelines |
| ğŸ–¼ï¸ **Computer Vision** | YOLO detection, SAM2 segmentation, OCR, face detection, image generation |
| âš¡ **Edge AI** | ONNX Runtime, TensorRT, INT8 quantization, model benchmarking |
| ğŸ”§ **Fine-Tuning** | LoRA/QLoRA fine-tuning with PEFT + Transformers |
| ğŸ§ª **MLOps** | MLflow + Weights & Biases experiment tracking |
| ğŸ›¡ï¸ **Guardrails** | Content filter (Detoxify), PII detection (Presidio), prompt injection defense |
| ğŸ“Š **Analytics** | Text-to-SQL, auto-chart generation (Plotly), report builder |
| ğŸ  **Ollama** | Local LLM deployment via docker-compose |
| ğŸ¯ **GPU Support** | CUDA-accelerated training, mixed precision (FP16/BF16) |
| ğŸ“‹ **Audit Logging** | Full AI interaction audit trail for compliance |
| ğŸš€ **One-Command Deploy** | Deploy to AWS, GCP, Azure, DigitalOcean, Railway, Fly.io, Render, or VPS |

## ğŸ“¦ Installation

Since **one-click-ai** is a CLI tool, it is recommended to install it globally using `uv`:

```bash
uv tool install one-click-ai
```

If your system doesn't have `uv` yet, follow the [installation guide here](https://docs.astral.sh/uv/getting-started/installation/).

Alternatively, you can use pip:

```bash
pip install one-click-ai
```

## ğŸš€ Usage

### Initialize a Full AI Project (everything enabled)

```bash
ocd-ai init my-ai-project --all
```

This creates a new folder `my-ai-project` with a complete production-ready AI backend.

### Initialize in the Current Directory

```bash
ocd-ai init .
```

### ğŸ¤– Chatbot (LLM Only)

```bash
ocd-ai init my-chatbot --llm-only --openai --docker
```

### ğŸ“š RAG Application

```bash
ocd-ai init my-rag-app --rag --openai --faiss --docker --ci-cd
```

### ğŸ¤ Voice Assistant

```bash
ocd-ai init my-voice-app --voice --voice-to-voice --openai --streaming --docker
```

### ğŸ‘ï¸ Vision + Emotion Analysis

```bash
ocd-ai init my-vision-app --vision --emotion --openai --google --docker
```

### ğŸ¤– AI Agent with Search & Memory

```bash
ocd-ai init my-agent --agents --search --memory --openai --streaming --docker --ci-cd
```

### ğŸš€ Full Multi-Provider Stack

```bash
ocd-ai init my-enterprise-app \
    --rag --agents --search --memory --streaming --voice --vision --emotion \
    --openai --anthropic --google --groq \
    --faiss --qdrant \
    --postgres --redis \
    --docker --ci-cd --iac --monitoring
```

### ğŸ”¬ ML Training Pipeline

```bash
ocd-ai init my-ml-project --ml-training --pytorch --sklearn --xgboost --mlops --docker
```

### ğŸ–¼ï¸ Computer Vision

```bash
ocd-ai init my-cv-project --computer-vision --yolo --sam --ocr --face-detection --gpu --docker
```

### ğŸ”§ LLM Fine-Tuning (LoRA/QLoRA)

```bash
ocd-ai init my-finetune --fine-tuning --pytorch --gpu --mlops --docker
```

### âš¡ Edge AI Deployment

```bash
ocd-ai init my-edge-project --edge-ai --onnx --tensorrt --quantization --docker
```

### ğŸ›¡ï¸ AI Guardrails

```bash
ocd-ai init my-safe-ai --guardrails --openai --rag --docker
```

### ğŸ“Š Conversational Analytics

```bash
ocd-ai init my-analytics --analytics --openai --docker
```

### ğŸ–¼ï¸ Image Generation

```bash
ocd-ai init my-image-gen --computer-vision --image-gen --gpu --docker
```

### ğŸš€ One-Command Deploy

Every generated project includes a `deploy.py` and `deploy.sh` that supports **8 deployment platforms** out of the box:

```bash
# Deploy to any platform (interactive wizard if no platform specified)
ocd-ai deploy

# Direct deploy to a specific platform
ocd-ai deploy aws           # AWS ECS (Fargate)
ocd-ai deploy gcp           # Google Cloud Run
ocd-ai deploy azure         # Azure Container Apps
ocd-ai deploy digitalocean  # DigitalOcean App Platform
ocd-ai deploy railway       # Railway
ocd-ai deploy fly           # Fly.io
ocd-ai deploy render        # Render
ocd-ai deploy vps           # Any VPS via SSH + Docker

# Build & push Docker image before deploying
ocd-ai deploy aws --build --push
```

## ğŸ›ï¸ CLI Flags

### Feature Flags

| Flag | Description |
|------|-------------|
| `--all` | Enable every feature, provider, vector store, database, and infrastructure option |
| `--llm-only` | Just LLM chat (no RAG, voice, vision, etc.) |
| `--rag` | RAG pipeline (ingestion, chunking, embedding, retrieval, generation) |
| `--voice` | Speech-to-Text + Text-to-Speech |
| `--voice-to-voice` | Voice conversation (implies `--voice` + `--streaming`) |
| `--vision` | Image/video analysis |
| `--emotion` | Emotion detection (audio + text) |
| `--search` | Web search with LLM summarization |
| `--agents` | ReAct-style AI agents with tool use |
| `--memory` | Short-term + long-term conversation memory |
| `--streaming` | SSE + WebSocket streaming |
| `--session` | Redis-backed session management |

### LLM Providers

| Flag | Provider |
|------|----------|
| `--openai` | OpenAI (GPT-4o, GPT-4, GPT-3.5) |
| `--anthropic` | Anthropic (Claude 3.5, Claude 3) |
| `--google` | Google (Gemini Pro, Gemini Flash) |
| `--groq` | Groq (Llama, Mixtral â€” ultra-fast inference) |
| `--grok` | xAI Grok |
| `--cohere` | Cohere (Command R+) |
| `--mistral` | Mistral AI (Mistral Large, Mixtral) |
| `--ollama` | Ollama (local models â€” Llama, Mistral, etc.) |
| `--all-providers` | Enable all providers |

### Vector Stores

| Flag | Store |
|------|-------|
| `--faiss` | Facebook AI Similarity Search (local, fast) |
| `--pinecone` | Pinecone (managed, scalable) |
| `--qdrant` | Qdrant (open-source, feature-rich) |
| `--weaviate` | Weaviate (hybrid search) |
| `--chroma` | ChromaDB (lightweight, embedded) |
| `--milvus` | Milvus (distributed, GPU-accelerated) |
| `--pgvector` | pgvector (PostgreSQL extension) |

### Databases

| Flag | Database |
|------|----------|
| `--postgres` | PostgreSQL (primary relational database) |
| `--mongodb` | MongoDB (document store) |
| `--redis` | Redis (caching, sessions, pub/sub) |
| `--all-databases` | Enable all databases |

### Infrastructure

| Flag | Description |
|------|-------------|
| `--docker` | Dockerfiles + docker-compose (dev & prod) + Nginx |
| `--ci-cd` | GitHub Actions workflows (test, lint, deploy) |
| `--iac` | Terraform (AWS) + Ansible server configuration |
| `--monitoring` | Prometheus + Grafana + alerting rules |

### ML / Training

| Flag | Description |
|------|-------------|
| `--ml-training` | Full ML training pipeline (trainer, predictor, data loader, model registry) |
| `--pytorch` | PyTorch models (MLP, CNN, LSTM, Transformer) |
| `--tensorflow` | TensorFlow/Keras models |
| `--sklearn` | scikit-learn pipelines (Random Forest, SVM, Gradient Boosting, auto-select) |
| `--xgboost` | XGBoost gradient boosting |
| `--lightgbm` | LightGBM gradient boosting |
| `--fine-tuning` | LLM fine-tuning with LoRA/QLoRA (PEFT + Transformers) |
| `--gpu` | Enable CUDA/GPU, mixed precision (FP16/BF16) |
| `--mlops` | MLflow + Weights & Biases experiment tracking |

### Computer Vision

| Flag | Description |
|------|-------------|
| `--computer-vision` | Computer vision module (inference, pre/post-processing) |
| `--yolo` | YOLOv8/v11 object detection (Ultralytics) |
| `--sam` | SAM2 image segmentation (Segment Anything) |
| `--ocr` | OCR text extraction (EasyOCR + Tesseract) |
| `--face-detection` | Face detection & recognition (face-recognition + MediaPipe) |
| `--image-gen` | Text-to-image generation (Stable Diffusion / Diffusers) |

### Edge AI

| Flag | Description |
|------|-------------|
| `--edge-ai` | Edge AI deployment module |
| `--onnx` | ONNX model conversion + ONNX Runtime inference |
| `--tensorrt` | TensorRT model optimization (NVIDIA) |
| `--quantization` | INT8 quantization (ONNX + HuggingFace Optimum) |

### Advanced Features

| Flag | Description |
|------|-------------|
| `--aggregator` | AI API aggregator pattern (multi-provider routing) |
| `--analytics` | Conversational analytics (Text-to-SQL + charts + reports) |
| `--guardrails` | AI safety (content filter, PII detection, prompt injection defense, audit) |
| `--multi-tenant` | Multi-tenant architecture support |
| `--ab-testing` | A/B testing framework for prompts/models |
| `--ollama-serve` | Local Ollama deployment in docker-compose |

## ğŸ“ Generated Project Structure

```
my-ai-project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚   â”‚   â”œâ”€â”€ config.py               # Pydantic settings & environment config
â”‚   â”‚   â”œâ”€â”€ dependencies.py         # Dependency injection
â”‚   â”‚   â”œâ”€â”€ exceptions.py           # Custom exception handlers
â”‚   â”‚   â”œâ”€â”€ api/v1/                 # API routes (versioned)
â”‚   â”‚   â”‚   â”œâ”€â”€ health.py           # Health check endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py             # LLM chat endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ rag.py              # RAG query endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ documents.py        # Document upload/management
â”‚   â”‚   â”‚   â”œâ”€â”€ voice.py            # STT/TTS endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ websocket.py        # WebSocket streaming
â”‚   â”‚   â”‚   â”œâ”€â”€ vision.py           # Image/video analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ emotion.py          # Emotion detection
â”‚   â”‚   â”‚   â”œâ”€â”€ search.py           # Web search
â”‚   â”‚   â”‚   â”œâ”€â”€ agents.py           # AI agent endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ sessions.py         # Session management
â”‚   â”‚   â”‚   â”œâ”€â”€ ml.py               # ML training & prediction
â”‚   â”‚   â”‚   â”œâ”€â”€ cv.py               # Computer vision endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ edge.py             # Edge AI (convert, benchmark)
â”‚   â”‚   â”‚   â”œâ”€â”€ analytics.py        # Text-to-SQL & charts
â”‚   â”‚   â”‚   â””â”€â”€ guardrails.py       # AI safety endpoints
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ ai/                 # LLM clients + provider factory
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ providers/      # OpenAI, Anthropic, Google, etc.
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm_client.py   # Base LLM interface
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ embeddings.py   # Embedding generation
â”‚   â”‚   â”‚   â”œâ”€â”€ rag/                # RAG pipeline
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py    # Document ingestion
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chunking.py     # Smart text chunking
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ retriever.py    # Vector retrieval
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ pipeline.py     # End-to-end RAG
â”‚   â”‚   â”‚   â”œâ”€â”€ multimodal/         # Voice, vision, emotion
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ stt.py          # Speech-to-Text
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tts.py          # Text-to-Speech
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ vision.py       # Vision analysis
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ emotion.py      # Emotion detection
â”‚   â”‚   â”‚   â”œâ”€â”€ agents/             # Agent framework
â”‚   â”‚   â”‚   â”œâ”€â”€ memory/             # Memory management
â”‚   â”‚   â”‚   â””â”€â”€ search/             # Web search
â”‚   â”‚   â”œâ”€â”€ ml/                     # ML training pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ trainer.py          # Unified trainer (PyTorch/sklearn/XGBoost)
â”‚   â”‚   â”‚   â”œâ”€â”€ predictor.py        # Model inference
â”‚   â”‚   â”‚   â”œâ”€â”€ data_loader.py      # Data loading & splitting
â”‚   â”‚   â”‚   â”œâ”€â”€ feature_engineering.py # Feature scaling, encoding
â”‚   â”‚   â”‚   â”œâ”€â”€ model_registry.py   # Model versioning & promotion
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluation.py       # Metrics (accuracy, F1, RMSE)
â”‚   â”‚   â”‚   â”œâ”€â”€ experiment.py       # MLflow/W&B tracking
â”‚   â”‚   â”‚   â”œâ”€â”€ pytorch_models.py   # MLP, CNN, LSTM, Transformer
â”‚   â”‚   â”‚   â”œâ”€â”€ sklearn_models.py   # RF, SVM, GB, auto-select
â”‚   â”‚   â”‚   â”œâ”€â”€ tf_models.py        # Keras models
â”‚   â”‚   â”‚   â””â”€â”€ fine_tuning.py      # LoRA/QLoRA fine-tuning
â”‚   â”‚   â”œâ”€â”€ cv/                     # Computer vision
â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py        # Unified CV pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessing.py    # Resize, normalize, augment
â”‚   â”‚   â”‚   â”œâ”€â”€ postprocessing.py   # NMS, drawing, formatting
â”‚   â”‚   â”‚   â”œâ”€â”€ yolo_detector.py    # YOLOv8/v11 detection
â”‚   â”‚   â”‚   â”œâ”€â”€ sam_segmenter.py    # SAM2 segmentation
â”‚   â”‚   â”‚   â”œâ”€â”€ ocr_engine.py       # EasyOCR + Tesseract
â”‚   â”‚   â”‚   â”œâ”€â”€ face_detector.py    # Face detection/recognition
â”‚   â”‚   â”‚   â””â”€â”€ image_generator.py  # Stable Diffusion generation
â”‚   â”‚   â”œâ”€â”€ edge/                   # Edge AI deployment
â”‚   â”‚   â”‚   â”œâ”€â”€ converter.py        # PyTorchâ†’ONNXâ†’TensorRT
â”‚   â”‚   â”‚   â”œâ”€â”€ optimizer.py        # Quantization, pruning
â”‚   â”‚   â”‚   â””â”€â”€ runtime.py          # ONNX Runtime inference
â”‚   â”‚   â”œâ”€â”€ analytics/              # Conversational analytics
â”‚   â”‚   â”‚   â”œâ”€â”€ text_to_sql.py      # NLâ†’SQL engine
â”‚   â”‚   â”‚   â”œâ”€â”€ chart_gen.py        # Plotly chart generation
â”‚   â”‚   â”‚   â””â”€â”€ report.py           # HTML report builder
â”‚   â”‚   â”œâ”€â”€ guardrails/             # AI safety
â”‚   â”‚   â”‚   â”œâ”€â”€ content_filter.py   # Toxicity detection (Detoxify)
â”‚   â”‚   â”‚   â”œâ”€â”€ pii_detector.py     # PII detection (Presidio)
â”‚   â”‚   â”‚   â”œâ”€â”€ prompt_injection.py # Injection defense
â”‚   â”‚   â”‚   â””â”€â”€ audit_logger.py     # Compliance audit trail
â”‚   â”‚   â”œâ”€â”€ services/               # Business logic layer
â”‚   â”‚   â”œâ”€â”€ models/                 # Pydantic schemas & enums
â”‚   â”‚   â”œâ”€â”€ db/                     # Database connections
â”‚   â”‚   â””â”€â”€ utils/                  # Logger, security, helpers
â”‚   â”œâ”€â”€ tests/                      # Test suite
â”‚   â”œâ”€â”€ vector_stores/              # Vector store implementations
â”‚   â”œâ”€â”€ middleware/                  # Error handling, rate limiting, logging
â”‚   â”œâ”€â”€ Dockerfile                  # Production Dockerfile
â”‚   â”œâ”€â”€ Dockerfile.dev              # Development Dockerfile
â”‚   â”œâ”€â”€ .env                        # Environment variables
â”‚   â””â”€â”€ .env.example                # Environment template
â”œâ”€â”€ docker-compose.dev.yml          # Development orchestration
â”œâ”€â”€ docker-compose.prod.yml         # Production orchestration
â”œâ”€â”€ nginx/
â”‚   â””â”€â”€ nginx.conf                  # Reverse proxy configuration
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ test.yml                # CI testing
â”‚       â”œâ”€â”€ lint.yml                # Code linting
â”‚       â””â”€â”€ deploy.yml              # Deployment pipeline
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ terraform/                  # AWS infrastructure
â”‚   â””â”€â”€ ansible/                    # Server configuration
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml              # Metrics collection
â”‚   â”œâ”€â”€ alerts.yml                  # Alert rules
â”‚   â””â”€â”€ grafana_dashboard.json      # Pre-built dashboards
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start.sh                    # Application launcher
â”‚   â””â”€â”€ health_check.py             # Health check script
â”œâ”€â”€ models/                         # Trained model storage
â”‚   â”œâ”€â”€ checkpoints/                # Training checkpoints
â”‚   â””â”€â”€ exported/                   # Production-ready models
â”œâ”€â”€ datasets/                       # Training data
â”‚   â”œâ”€â”€ raw/                        # Raw datasets
â”‚   â””â”€â”€ processed/                  # Processed features
â”œâ”€â”€ experiments/                    # MLflow/W&B experiment logs
â”œâ”€â”€ Makefile                        # Common commands
â”œâ”€â”€ deploy.py                       # Cross-platform deploy script (Python)
â”œâ”€â”€ deploy.sh                       # Deploy script (Bash)
â”œâ”€â”€ .gitignore                      # Git ignore rules
â””â”€â”€ DEVELOPMENT_GUIDE.md            # Getting started guide
```

### ğŸš€ Built for the Future (Extensibility)

This structure is intentionally designed for scaling into a full-stack or microservices architecture:

- **Full-Stack Ready:** Need a frontend? Add a `frontend/` folder (React, Next.js, Streamlit, Gradio) at the root.
- **Microservices Ready:** Plug in other services like `ml-training/`, `data-pipeline/`, or `notification-service/` alongside the backend.
- **Multi-Model Ready:** Each AI provider is isolated behind a factory pattern â€” adding a new provider is one file.
- **ML/CV Pipeline Ready:** Training, inference, and edge deployment modules are fully isolated and can scale independently.
- **Simplified Orchestration:** New services integrate into the root `docker-compose.yml` and CI/CD pipelines seamlessly.
- **Guardrails by Default:** Content safety, PII protection, and prompt injection defense can be applied to any endpoint.

## ğŸ”§ Tech Stack

| Category | Technologies |
|----------|-------------|
| **Framework** | FastAPI â‰¥ 0.115 |
| **Runtime** | Python â‰¥ 3.11, uvicorn |
| **Package Manager** | uv |
| **Validation** | Pydantic v2, pydantic-settings |
| **LLM Providers** | OpenAI, Anthropic, Google, Groq, Grok, Cohere, Mistral, Ollama, DeepSeek, Meta |
| **Vector Stores** | FAISS, Pinecone, Qdrant, Weaviate, ChromaDB, Milvus, pgvector, LanceDB |
| **Voice** | Whisper, Deepgram, whisper-local (STT) Â· OpenAI TTS, ElevenLabs, Bark (TTS) |
| **Vision** | GPT-4.1, Claude Opus 4, Gemini 2.5 Pro Vision |
| **Emotion** | Hume AI, Affectiva, LLM-based fallback |
| **Search** | Tavily, Serper, DuckDuckGo |
| **ML Frameworks** | PyTorch, TensorFlow/Keras, scikit-learn, XGBoost, LightGBM |
| **Computer Vision** | YOLO (Ultralytics), SAM2, EasyOCR, Tesseract, face-recognition, MediaPipe, Diffusers |
| **Edge AI** | ONNX, ONNX Runtime, TensorRT, HuggingFace Optimum |
| **Fine-Tuning** | PEFT (LoRA/QLoRA), Transformers, TRL, bitsandbytes |
| **MLOps** | MLflow, Weights & Biases |
| **Guardrails** | Detoxify, Presidio (PII), custom prompt injection defense |
| **Analytics** | SQLAlchemy, sqlparse, Plotly |
| **Databases** | PostgreSQL, MongoDB, Redis |
| **Containers** | Docker + docker-compose + Nginx |
| **CI/CD** | GitHub Actions |
| **IaC** | Terraform (AWS) + Ansible |
| **Monitoring** | Prometheus + Grafana + Alertmanager |

## âš™ï¸ Configuration

On first run, `ocd-ai` will ask for your **GitHub username**, **DockerHub username**, **default LLM provider**, and **default vector store**. These are saved in `~/.config/one-click-ai/config.toml` so you never have to type them again.

You can reset your configuration at any time by editing or deleting the config file.

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **Fork** the repository
2. **Clone** your fork: `git clone https://github.com/your-username/one-click-ai.git`
3. **Install dependencies:** `uv sync` or `pip install -e .`
4. **Create a branch:** `git checkout -b feature/my-feature`
5. **Make your changes** â€” add generators in `src/one_click_ai/generator.py` or new templates in `src/one_click_ai/templates/`
6. **Test locally:** `ocd-ai init test-project --all`
7. **Submit a Pull Request** ğŸ‰

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

## ğŸ‘¨â€ğŸ’» Author

**Mohammad Asif Khan**

- GitHub: [@aktonay](https://github.com/aktonay)
- LinkedIn: [Mohammad Asif Khan](https://www.linkedin.com/in/mohammad-asif-khan-tonay-795b641b6)
- Website: [sparktech.agency](https://www.sparktech.agency/)

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

<p align="center">
  Made with â¤ï¸ for the AI developer community
  <br>
  <a href="#top">Back to Top â¬†</a>
</p>
