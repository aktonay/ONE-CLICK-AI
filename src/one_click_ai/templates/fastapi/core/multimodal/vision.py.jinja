"""Image & video analysis using vision models."""

from typing import Dict, Optional
from app.config import get_settings
import base64
import logging

logger = logging.getLogger(__name__)


class VisionClient:
    """Vision analysis â€” supports GPT-4o, Claude, Gemini."""

    def __init__(self):
        self.settings = get_settings()
        self.provider = self.settings.VISION_PROVIDER

    async def analyze_image(
        self, image_bytes: bytes, prompt: str, content_type: str = "image/jpeg"
    ) -> Dict:
        b64 = base64.b64encode(image_bytes).decode("utf-8")
        data_url = f"data:{content_type};base64,{b64}"

        if self.provider == "openai":
            return await self._openai_vision(data_url, prompt)
        else:
            return await self._openai_vision(data_url, prompt)

    async def _openai_vision(self, data_url: str, prompt: str) -> Dict:
        import openai

        client = openai.AsyncOpenAI(api_key=self.settings.OPENAI_API_KEY)
        response = await client.chat.completions.create(
            model=self.settings.VISION_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": data_url}},
                    ],
                }
            ],
            max_tokens=1024,
        )
        return {
            "description": response.choices[0].message.content or "",
            "model": response.model,
        }

    async def analyze_video_frames(
        self, frames: list[bytes], prompt: str, content_type: str = "image/jpeg"
    ) -> Dict:
        """Analyse multiple frames extracted from a video."""
        descriptions = []
        for frame in frames[:10]:  # Limit to 10 frames
            result = await self.analyze_image(frame, prompt, content_type)
            descriptions.append(result["description"])

        # Summarise all frame descriptions
        from app.core.ai.factory import get_llm_client

        client = get_llm_client()
        summary = await client.chat(
            messages=[
                {
                    "role": "system",
                    "content": "Combine these video frame descriptions into a coherent summary.",
                },
                {"role": "user", "content": "\n\n".join(descriptions)},
            ],
            temperature=0.3,
        )
        return {"summary": summary["content"], "frames_analyzed": len(descriptions)}
