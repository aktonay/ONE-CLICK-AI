{# Image Generator #}
"""
Text-to-image generation using Stable Diffusion / Diffusers.
"""

import logging
from typing import Any, Dict, Optional
from pathlib import Path

logger = logging.getLogger(__name__)


class ImageGenerator:
    """Stable Diffusion / FLUX image generation."""

    def __init__(
        self,
        model_id: str = "stabilityai/stable-diffusion-xl-base-1.0",
        device: str = "{{ 'cuda' if gpu else 'cpu' }}",
    ):
        self.model_id = model_id
        self.device = device
        self._pipe = None

    def _load(self):
        if self._pipe is not None:
            return
        import torch
        from diffusers import StableDiffusionXLPipeline

        self._pipe = StableDiffusionXLPipeline.from_pretrained(
            self.model_id,
            torch_dtype=torch.float16 if "cuda" in self.device else torch.float32,
        ).to(self.device)

        # Enable memory-efficient attention
        if "cuda" in self.device:
            self._pipe.enable_model_cpu_offload()
        logger.info(f"Image generation model loaded: {self.model_id}")

    def generate(
        self,
        prompt: str,
        negative_prompt: str = "low quality, blurry, distorted",
        width: int = 1024,
        height: int = 1024,
        steps: int = 30,
        guidance_scale: float = 7.5,
        seed: Optional[int] = None,
        output_path: str = "outputs/generated.png",
    ) -> Dict[str, Any]:
        """Generate image from text prompt."""
        import torch
        self._load()

        generator = torch.Generator(device=self.device)
        if seed is not None:
            generator.manual_seed(seed)

        image = self._pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            num_inference_steps=steps,
            guidance_scale=guidance_scale,
            generator=generator,
        ).images[0]

        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        image.save(output_path)

        return {
            "output_path": output_path,
            "prompt": prompt,
            "width": width,
            "height": height,
            "steps": steps,
            "seed": seed,
        }

    def generate_batch(self, prompts: list, **kwargs) -> list:
        """Generate multiple images."""
        return [self.generate(p, **kwargs) for p in prompts]
